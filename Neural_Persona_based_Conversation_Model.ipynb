{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural-Persona-based-Conversation-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1h2Ck6oRRlikXABTsW6Gkq767a6_3vQ3X",
      "authorship_tag": "ABX9TyO/hrGWmr0Fnyo96VnVt3/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amithm92/Neural-Persona-based-Conversation-Model-Python-Version/blob/master/Neural_Persona_based_Conversation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gatjp9KDOlm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "3151898c-25d8-4a67-d30a-c0f0c3bac890"
      },
      "source": [
        "!git clone https://github.com/amithm92/Neural-Persona-based-Conversation-Model-Python-Version.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Neural-Persona-based-Conversation-Model-Python-Version'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 29 (delta 0), reused 0 (delta 0), pack-reused 26\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axDYTRayqT1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -r /content/Neural-Persona-based-Conversation-Model-Python-Version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjUr9BY1O15h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -a \"/content/drive/My Drive/Data/OpenSubData/.\" /content/Neural-Persona-based-Conversation-Model-Python-Version/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLxbHjiomkuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3121a00e-9cec-40c3-f575-7469733059bd"
      },
      "source": [
        "cd Neural-Persona-based-Conversation-Model-Python-Version/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Neural-Persona-based-Conversation-Model-Python-Version\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcHHOMHchhX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "1c7655cb-e67a-4f4f-9cc0-1714ca7c8ad6"
      },
      "source": [
        "!python /content/Neural-Persona-based-Conversation-Model-Python-Version/train.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training in persona mode\n",
            "iter  0\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "perp 25068.774799730912\n",
            "iter  1\n",
            "perp 20610.5718084766\n",
            "finished saving\n",
            "iter  2\n",
            "perp 3119511.5368606597\n",
            "finished saving\n",
            "iter  3\n",
            "perp 69797.11594485345\n",
            "finished saving\n",
            "iter  4\n",
            "perp 60156.36701303772\n",
            "finished saving\n",
            "iter  5\n",
            "perp 9146.801675720368\n",
            "finished saving\n",
            "iter  6\n",
            "perp 8.969775335737868e+18\n",
            "finished saving\n",
            "iter  7\n",
            "perp 225837.91316751376\n",
            "finished saving\n",
            "iter  8\n",
            "perp 11630.533999563475\n",
            "finished saving\n",
            "iter  9\n",
            "perp 4320.210546752091\n",
            "finished saving\n",
            "iter  10\n",
            "perp 3426.637294464231\n",
            "finished saving\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTb17EnEs3Rf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a68614ae-a670-4620-de68-de575e58503e"
      },
      "source": [
        "!python /content/Neural-Persona-based-Conversation-Model-Python-Version/decode.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoding in persona mode\n",
            "read model done\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "decoding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1uWiyk6s5So",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "c3049c16-33e3-4b67-d149-bd44b12b548e"
      },
      "source": [
        "with open(\"/content/Neural-Persona-based-Conversation-Model-Python-Version/data/s_given_t_dialogue_length2_3.txt\") as myfile:\n",
        "  i = 0\n",
        "  for line in myfile:\n",
        "    print(line)\n",
        "    i = i+1\n",
        "    if i==10:\n",
        "      break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38 53 12 11 28 433 10076 73 44 15860 11 535 30 12 104 7|27 185 22 100 6567 288\n",
            "\n",
            "27 185 22 100 6567 288|15 120 51 44 12029 262 10 1\n",
            "\n",
            "15 120 51 44 12029 262 10 1|28 566 11 100 6567 288 7\n",
            "\n",
            "28 566 11 100 6567 288 7|483 73 4 2048 9 1289 16 154\n",
            "\n",
            "483 73 4 2048 9 1289 16 154|53 28 185 11 100 6567 288 21 216 16 119 15860 7\n",
            "\n",
            "53 28 185 11 100 6567 288 21 216 16 119 15860 7|1 15860 22 27 382\n",
            "\n",
            "1 15860 22 27 382|12 41 37 27 734\n",
            "\n",
            "12 41 37 27 734|5 85 205 4 1560\n",
            "\n",
            "5 85 205 4 1560|12 41 28 324 9 10410 88 9 100 7800\n",
            "\n",
            "12 41 28 324 9 10410 88 9 100 7800|53 51 2057 110 4 2048 20 14\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvZ-7tDjuVdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hello"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}